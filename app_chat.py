"""
Streamlit UI for Daum Finance Q&A Chatbot - GPT Style Chat Interface
"""

import streamlit as st
import os
from dotenv import load_dotenv

from state import init_session_state
from intent import analyze_intent, _extract_stock_name
from planner import create_plan
from daum_fetch import fetch
from summarizer import summarize_results
from answer import generate_answer
from config import CACHE_TTL_PRICE, CACHE_TTL_NEWS, CACHE_TTL_SEARCH, get_env
from endpoints import get_search_url
from parsers import parse_search_results
from conversation import is_general_conversation, generate_conversational_response

# Load environment variables
load_dotenv()


def _process_stock_query(user_input: str, state, show_steps: bool, use_llm: bool):
    """
    Process stock-related query
    """
    response_placeholder = st.empty()

    try:
        # STEP 1: Analyze intent
        if show_steps:
                with st.status("ğŸ” ì§ˆë¬¸ ë¶„ì„ ì¤‘...", expanded=False) as status:
                    intent = analyze_intent(user_input, use_llm=use_llm)

                    # Check memory for stock context
                    if not intent.stock_code and state.memory.has_stock_context():
                        intent.stock_code = state.memory.last_stock_code
                        intent.stock_name = state.memory.last_stock_name

                    st.markdown(f"- ì§ˆë¬¸ ìœ í˜•: **{intent.question_type}**")
                    st.markdown(f"- ëŒ€ìƒ ì¢…ëª©: **{intent.stock_name or 'ë¯¸í™•ì¸'}** ({intent.stock_code or 'ë¯¸í™•ì¸'})")
                    status.update(label="âœ… ì§ˆë¬¸ ë¶„ì„ ì™„ë£Œ", state="complete")
            else:
                intent = analyze_intent(user_input, use_llm=use_llm)

                if not intent.stock_code and state.memory.has_stock_context():
                    intent.stock_code = state.memory.last_stock_code
                    intent.stock_name = state.memory.last_stock_name

            # If no stock code, try to search
            if not intent.stock_code:
                stock_name = _extract_stock_name(user_input)

                if stock_name:
                    with st.spinner("ğŸ” ì¢…ëª© ê²€ìƒ‰ ì¤‘..."):
                        search_url = get_search_url(stock_name)
                        search_result = fetch(search_url, use_cache=True, cache_ttl=120)

                        if search_result.success:
                            candidates = parse_search_results(search_result.content)

                            if len(candidates) == 0:
                                response = f"âŒ '{stock_name}' ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nì •í™•í•œ ì¢…ëª©ëª… ë˜ëŠ” 6ìë¦¬ ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
                                response_placeholder.markdown(response)
                                state.add_assistant_message(response)
                                st.stop()

                            elif len(candidates) == 1:
                                intent.stock_code = candidates[0]['code']
                                intent.stock_name = candidates[0]['name']
                                st.success(f"âœ… {intent.stock_name} ì¢…ëª©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!")

                            else:
                                # Multiple results - set pending choice
                                state.pending_choice.candidates = candidates
                                state.pending_choice.original_user_query = user_input
                                state.pending_choice.next_action = intent.question_type

                                response = f"ğŸ” '{stock_name}' ê²€ìƒ‰ ê²°ê³¼ê°€ **{len(candidates)}ê°œ** ìˆìŠµë‹ˆë‹¤.\n\nì•„ë˜ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”."
                                response_placeholder.markdown(response)
                                state.add_assistant_message(response)
                                st.rerun()
                else:
                    response = "âŒ ì¢…ëª©ì„ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n**ì¢…ëª©ëª…** ë˜ëŠ” **6ìë¦¬ ì½”ë“œ**ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\n\nì˜ˆ: `ì‚¼ì„±ì „ì`, `005930`"
                    response_placeholder.markdown(response)
                    state.add_assistant_message(response)
                    st.stop()

            # Update memory
            state.memory.update(
                stock_code=intent.stock_code,
                stock_name=intent.stock_name,
                question_type=intent.question_type
            )

            # STEP 2: Create plan
            if show_steps:
                with st.status("ğŸ“‹ ì •ë³´ ìˆ˜ì§‘ ê³„íš ìˆ˜ë¦½ ì¤‘...", expanded=False) as status:
                    plans = create_plan(intent)

                    if plans:
                        for i, plan in enumerate(plans, 1):
                            st.markdown(f"{i}. {plan.description}")
                    status.update(label="âœ… ê³„íš ìˆ˜ë¦½ ì™„ë£Œ", state="complete")
            else:
                plans = create_plan(intent)

            if not plans:
                response = "âŒ ì •ë³´ ìˆ˜ì§‘ ê³„íšì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                response_placeholder.markdown(response)
                state.add_assistant_message(response)
                st.stop()

            # STEP 3: Fetch data
            if show_steps:
                with st.status("ğŸ“Š ë°ì´í„° ìˆ˜ì§‘ ì¤‘...", expanded=False) as status:
                    fetch_results = []

                    for i, plan in enumerate(plans):
                        st.markdown(f"â³ {plan.description}...")

                        # Determine cache TTL
                        if 'news' in plan.url.lower() or 'disclosure' in plan.url.lower():
                            cache_ttl = CACHE_TTL_NEWS
                        elif 'price' in plan.url.lower() or 'quote' in plan.url.lower():
                            cache_ttl = CACHE_TTL_PRICE
                        else:
                            cache_ttl = CACHE_TTL_SEARCH

                        result = fetch(
                            url=plan.url,
                            use_cache=True,
                            cache_ttl=cache_ttl,
                            is_json=plan.is_json
                        )

                        fetch_results.append((result, plan))

                    status.update(label="âœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ", state="complete")
            else:
                with st.spinner("ğŸ“Š ë‹¤ìŒ ê¸ˆìœµì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                    fetch_results = []

                    for plan in plans:
                        if 'news' in plan.url.lower() or 'disclosure' in plan.url.lower():
                            cache_ttl = CACHE_TTL_NEWS
                        elif 'price' in plan.url.lower() or 'quote' in plan.url.lower():
                            cache_ttl = CACHE_TTL_PRICE
                        else:
                            cache_ttl = CACHE_TTL_SEARCH

                        result = fetch(
                            url=plan.url,
                            use_cache=True,
                            cache_ttl=cache_ttl,
                            is_json=plan.is_json
                        )

                        fetch_results.append((result, plan))

            # Check if all failed
            failed_count = sum(1 for result, _ in fetch_results if not result.success)

            # If some succeeded, continue with those results
            # Only show error if ALL failed
            if failed_count == len(plans) and failed_count > 0:
                # Show detailed error for debugging
                error_details = []
                for result, plan in fetch_results:
                    if not result.success:
                        error_details.append(f"- {plan.description}: {result.error_message or 'Unknown error'}")

                response = f"âŒ ë‹¤ìŒ ê¸ˆìœµì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"

                # Add debug info in development/debugging
                if get_env('DEBUG_MODE', 'false').lower() == 'true':
                    response += "**ë””ë²„ê·¸ ì •ë³´:**\n" + "\n".join(error_details) + "\n\n"

                response += "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

                response_placeholder.markdown(response)
                state.add_assistant_message(response)
                st.stop()

            elif failed_count > 0:
                # Some failed but some succeeded - show warning
                success_count = len(plans) - failed_count
                st.warning(f"âš ï¸ ì¼ë¶€ ë°ì´í„° ì†ŒìŠ¤ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({success_count}/{len(plans)} ì„±ê³µ). ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.")

            # STEP 4: Summarize
            summaries = summarize_results(fetch_results, plans)

            # Store in memory
            state.memory.last_sources = [
                {"type": s.source_type, "snippet": s.evidence_snippet}
                for s in summaries
            ]

            # STEP 5: Generate answer
            if show_steps:
                with st.status("âœï¸ ë‹µë³€ ìƒì„± ì¤‘...", expanded=False) as status:
                    answer_text = generate_answer(
                        intent=intent,
                        plans=plans,
                        summaries=summaries,
                        use_llm=use_llm
                    )
                    status.update(label="âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ", state="complete")
            else:
                with st.spinner("âœï¸ ë‹µë³€ ìƒì„± ì¤‘..."):
                    answer_text = generate_answer(
                        intent=intent,
                        plans=plans,
                        summaries=summaries,
                        use_llm=use_llm
                    )

            # Display answer
            response_placeholder.markdown(answer_text)

            # Add to history
            state.add_assistant_message(answer_text)

        except Exception as e:
            error_msg = f"âŒ **ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤**\n\n```\n{str(e)}\n```\n\nì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            response_placeholder.markdown(error_msg)
            state.add_assistant_message(error_msg)

# Page configuration
st.set_page_config(
    page_title="ë‹¤ìŒ ê¸ˆìœµ íˆ¬ì ì±—ë´‡",
    page_icon="ğŸ’¬",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS for GPT-like interface
st.markdown("""
<style>
    /* Hide Streamlit branding */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* Main chat container */
    .main {
        padding: 0;
    }
    
    /* Chat message styling */
    .stChatMessage {
        padding: 1rem 1.5rem;
    }
    
    /* User message background */
    [data-testid="stChatMessageContent"] {
        background-color: transparent;
    }
    
    /* Input styling */
    .stChatInputContainer {
        border-top: 1px solid #e0e0e0;
        padding: 1rem;
        background: white;
    }
    
    /* Button styling */
    .stButton > button {
        border-radius: 8px;
        font-weight: 500;
    }
    
    /* Title */
    h1 {
        text-align: center;
        padding: 1.5rem 0;
        margin: 0;
        border-bottom: 1px solid #e0e0e0;
        background: white;
    }
    
    /* Status boxes */
    .element-container:has(.streamlit-expanderHeader) {
        border-radius: 8px;
        overflow: hidden;
    }
    
    /* Quick action buttons */
    .quick-action-btn {
        background: #f0f0f0;
        border: 1px solid #d0d0d0;
        border-radius: 6px;
        padding: 0.5rem 1rem;
        margin: 0.25rem;
        cursor: pointer;
        display: inline-block;
        font-size: 0.9rem;
    }
    
    .quick-action-btn:hover {
        background: #e0e0e0;
    }
    
    /* Welcome message */
    .welcome-container {
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
        height: 60vh;
        text-align: center;
    }
    
    .welcome-title {
        font-size: 2.5rem;
        font-weight: 700;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    .welcome-subtitle {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    
    .example-questions {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
        gap: 1rem;
        max-width: 800px;
        margin: 0 auto;
        padding: 0 1rem;
    }
    
    .example-card {
        background: #f8f9fa;
        border: 1px solid #e0e0e0;
        border-radius: 12px;
        padding: 1rem;
        cursor: pointer;
        transition: all 0.2s;
    }
    
    .example-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        border-color: #667eea;
    }
    
    .example-icon {
        font-size: 1.5rem;
        margin-bottom: 0.5rem;
    }
    
    .example-text {
        font-size: 0.95rem;
        color: #333;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
state = init_session_state(st.session_state)

# Sidebar
with st.sidebar:
    st.markdown("### âš™ï¸ ì„¤ì •")
    
    use_llm = st.checkbox(
        "ğŸ¤– AI ë‹µë³€ ì‚¬ìš©",
        value=True,  # ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½
        help="OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤"
    )
    
    show_steps = st.checkbox(
        "ğŸ“Š ì²˜ë¦¬ ê³¼ì • ë³´ê¸°",
        value=True,  # ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½
        help="ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ í‘œì‹œí•©ë‹ˆë‹¤"
    )
    
    st.markdown("---")
    
    # Current context
    if state.memory.has_stock_context():
        st.markdown("### ğŸ“Œ í˜„ì¬ ì¢…ëª©")
        st.info(f"**{state.memory.last_stock_name}**\n\n({state.memory.last_stock_code})")
        
        if st.button("ğŸ”„ ì¢…ëª© ì´ˆê¸°í™”", use_container_width=True):
            state.memory.clear()
            st.success("ì¢…ëª©ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤")
            st.rerun()
    
    st.markdown("---")
    
    # Chat history management
    st.markdown("### ğŸ’¬ ëŒ€í™” ê´€ë¦¬")
    
    if state.chat_history:
        st.caption(f"ì´ {len(state.chat_history)}ê°œì˜ ë©”ì‹œì§€")
        
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ", use_container_width=True):
            state.reset()
            st.success("ëŒ€í™” ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤")
            st.rerun()
    else:
        st.caption("ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤")
    
    st.markdown("---")
    
    # Guide
    st.markdown("### ğŸ“– ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown("""
    **ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œ:**
    - ì‚¼ì„±ì „ì í˜„ì¬ê°€ëŠ”?
    - ë‰´ìŠ¤ ë³´ì—¬ì¤˜
    - íˆ¬ììë“¤ ì˜ê²¬ì€?
    - ìµœê·¼ ê³µì‹œ ìˆì–´?
    
    **ğŸ¯ íŠ¹ì§•:**
    - í›„ì† ì§ˆë¬¸ ì‹œ ì¢…ëª© ìë™ ê¸°ì–µ
    - ë‹¤ìŒ ê¸ˆìœµ ì‹¤ì‹œê°„ ë°ì´í„°
    - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ë°©ì‹
    """)
    
    st.markdown("---")
    st.caption("âš ï¸ íˆ¬ì íŒë‹¨ì€ ë³¸ì¸ ì±…ì„ì…ë‹ˆë‹¤")

# Main title
st.title("ğŸ’¬ ë‹¤ìŒ ê¸ˆìœµ íˆ¬ì ì±—ë´‡")

# Welcome screen (only if no chat history)
if not state.chat_history:
    st.markdown("""
    <div class="welcome-container">
        <div class="welcome-title">ë‹¤ìŒ ê¸ˆìœµ íˆ¬ì ì±—ë´‡</div>
        <div class="welcome-subtitle">ì¢…ëª© ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¡°íšŒí•˜ê³  íˆ¬ì íŒë‹¨ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤</div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### ğŸ’¡ ì§ˆë¬¸ ì˜ˆì‹œë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•´ë³´ì„¸ìš”")
    
    # Example questions
    examples = [
        {"icon": "ğŸ“ˆ", "text": "í‚¤ì›€ì¦ê¶Œ ì§€ê¸ˆ ì‚¬ë©´ ì¢‹ì„ê¹Œ?"},
        {"icon": "ğŸ“°", "text": "ì‚¼ì„±ì „ì ê±°ë˜ í˜„í™©?"},
        {"icon": "ğŸ’¬", "text": "í˜„ëŒ€ì°¨ ê´€ë ¨ ì‚¬ëŒë“¤ ì˜ê²¬ì´ ì–´ë•Œ?"},
        {"icon": "ğŸ“Š", "text": "ë„¤ì´ë²„ ì£¼ê°€ëŠ”?"},
    ]
    
    cols = st.columns(len(examples))
    for i, (col, example) in enumerate(zip(cols, examples)):
        with col:
            if st.button(
                f"{example['icon']}\n\n{example['text']}", 
                key=f"example_{i}",
                use_container_width=True
            ):
                st.session_state['example_question'] = example['text']
                st.rerun()

# Display chat history
for msg in state.chat_history:
    with st.chat_message(msg.role):
        st.markdown(msg.content)

# Handle stock selection (HITL)
if state.pending_choice.is_pending():
    with st.chat_message("assistant"):
        st.markdown("ğŸ” **ì—¬ëŸ¬ ì¢…ëª©ì´ ê²€ìƒ‰ë˜ì—ˆìŠµë‹ˆë‹¤. í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:**")
        
        # Display options as buttons
        selected_code = None
        cols = st.columns(min(len(state.pending_choice.candidates), 3))
        
        for idx, candidate in enumerate(state.pending_choice.candidates):
            col_idx = idx % 3
            with cols[col_idx]:
                if st.button(
                    f"**{candidate['name']}**\n{candidate['code']}\n{candidate.get('market', '')}",
                    key=f"stock_choice_{candidate['code']}",
                    use_container_width=True
                ):
                    selected_code = candidate['code']
                    selected_name = candidate['name']
                    
                    # Update memory
                    state.memory.update(
                        stock_code=selected_code,
                        stock_name=selected_name
                    )
                    
                    # Add confirmation message
                    state.add_assistant_message(
                        f"âœ… **{selected_name} ({selected_code})** ì¢…ëª©ì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤."
                    )
                    
                    # Clear pending and rerun
                    state.pending_choice.clear()
                    st.rerun()
        
        if st.button("âŒ ì·¨ì†Œ", key="cancel_choice"):
            state.pending_choice.clear()
            state.add_assistant_message("ì¢…ëª© ì„ íƒì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”.")
            st.rerun()

# Quick actions (if stock context exists)
if state.memory.has_stock_context() and not state.pending_choice.is_pending():
    with st.container():
        st.markdown("##### ğŸ’¡ ë¹ ë¥¸ ì§ˆë¬¸")
        quick_questions = [
            "í˜„ì¬ê°€ëŠ”?",
            "ë‰´ìŠ¤ ë³´ì—¬ì¤˜",
            "íˆ¬ì ì˜ê²¬ì€?",
            "ê³µì‹œ ìˆì–´?",
            "ì°¨íŠ¸ ì–´ë•Œ?"
        ]
        
        cols = st.columns(len(quick_questions))
        for col, question in zip(cols, quick_questions):
            with col:
                if st.button(question, key=f"quick_{question}", use_container_width=True):
                    st.session_state['quick_input'] = question
                    st.rerun()

# Handle quick input
if 'quick_input' in st.session_state:
    user_input = st.session_state['quick_input']
    del st.session_state['quick_input']
elif 'example_question' in st.session_state:
    user_input = st.session_state['example_question']
    del st.session_state['example_question']
else:
    user_input = st.chat_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”... (ì˜ˆ: ì‚¼ì„±ì „ì ì‹œì„¸ëŠ”?)",
        key="chat_input",
        disabled=state.pending_choice.is_pending()
    )

# Process user input
if user_input and not state.pending_choice.is_pending():
    # Add user message
    state.add_user_message(user_input)
    
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # Check if it's a general conversation
    if is_general_conversation(user_input):
        with st.chat_message("assistant"):
            # Prepare stock context for conversational response
            stock_ctx = None
            if state.memory.has_stock_context():
                stock_ctx = {
                    'name': state.memory.last_stock_name,
                    'code': state.memory.last_stock_code
                }
            
            # Generate conversational response
            with st.spinner("ğŸ’­ ìƒê°í•˜ëŠ” ì¤‘..."):
                response = generate_conversational_response(
                    user_input=user_input,
                    chat_history=state.get_recent_messages(6),
                    stock_context=stock_ctx,
                    use_llm=use_llm
                )
            
            st.markdown(response)
            state.add_assistant_message(response)
    else:
        # Process stock-related query
        with st.chat_message("assistant"):
            _process_stock_query(user_input, state, show_steps, use_llm)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray; font-size: 0.85rem; padding: 1rem;'>
    <p><strong>ğŸ’¬ ë‹¤ìŒ ê¸ˆìœµ íˆ¬ì ì±—ë´‡</strong></p>
    <p>ë³¸ ì„œë¹„ìŠ¤ëŠ” ë‹¤ìŒ ê¸ˆìœµ(finance.daum.net) ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.</p>
    <p>íˆ¬ì íŒë‹¨ ë° ê²°ê³¼ì— ëŒ€í•œ ì±…ì„ì€ íˆ¬ìì ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤.</p>
</div>
""", unsafe_allow_html=True)
