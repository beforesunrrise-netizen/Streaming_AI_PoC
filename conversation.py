"""
GPT-style conversational response generation
Handles general questions and maintains conversation context
"""

from typing import List, Optional
from config import get_env
from state import ChatMessage


def is_general_conversation(user_input: str) -> bool:
    """
    Check if user input is a general conversation (not stock-specific query)
    
    Args:
        user_input: User's input text
        
    Returns:
        True if it's a general conversation, False if it's a stock query
    """
    # Keywords that indicate stock-related queries
    stock_keywords = [
        'ì¢…ëª©', 'ì£¼ê°€', 'ì‹œì„¸', 'ë§¤ìˆ˜', 'ë§¤ë„', 'íˆ¬ì', 'ê±°ë˜ëŸ‰', 
        'í˜¸ê°€', 'ë‰´ìŠ¤', 'ê³µì‹œ', 'ì°¨íŠ¸', 'ìƒí•œê°€', 'í•˜í•œê°€', 'ë“±ë½',
        'ì „ì', 'ì¦ê¶Œ', 'ì€í–‰', 'í™”í•™', 'ì œì•½', 'ê±´ì„¤', 'ìë™ì°¨'
    ]
    
    # Check if input contains stock-related keywords
    user_input_lower = user_input.lower()
    has_stock_keyword = any(keyword in user_input_lower for keyword in stock_keywords)
    
    # Check if input contains numbers (likely stock codes)
    has_numbers = any(char.isdigit() for char in user_input)
    
    # General conversation patterns
    greeting_patterns = ['ì•ˆë…•', 'í•˜ì´', 'í—¬ë¡œ', 'ë°˜ê°€', 'ì¢‹ì€']
    question_patterns = ['ì–´ë–»ê²Œ', 'ë¬´ì—‡', 'ì™œ', 'ì–´ë””', 'ëˆ„êµ¬', 'ì–¸ì œ']
    thanks_patterns = ['ê³ ë§ˆ', 'ê°ì‚¬', 'ë•¡í', 'ã„³']
    
    is_greeting = any(pattern in user_input_lower for pattern in greeting_patterns)
    is_question = any(pattern in user_input_lower for pattern in question_patterns)
    is_thanks = any(pattern in user_input_lower for pattern in thanks_patterns)
    
    # Short messages (< 5 chars) are usually general
    is_short = len(user_input) < 5
    
    # Decision logic
    if has_stock_keyword or has_numbers:
        return False  # Stock query
    
    if is_greeting or is_thanks or (is_short and not has_stock_keyword):
        return True  # General conversation
    
    return False


def generate_conversational_response(
    user_input: str,
    chat_history: List[ChatMessage],
    stock_context: Optional[dict] = None,
    use_llm: bool = True
) -> str:
    """
    Generate conversational response using LLM
    
    Args:
        user_input: User's input text
        chat_history: Recent chat history
        stock_context: Current stock context (if any)
        use_llm: Whether to use LLM (default: True)
        
    Returns:
        Conversational response text
    """
    # Fallback responses for common patterns (when LLM is not available)
    if not use_llm:
        return _generate_fallback_response(user_input, stock_context)
    
    # Check if LLM is available
    api_key = get_env('ANTHROPIC_API_KEY') or get_env('OPENAI_API_KEY')
    if not api_key:
        return _generate_fallback_response(user_input, stock_context)
    
    # Prepare conversation history
    history_text = ""
    if chat_history:
        recent_history = chat_history[-6:]  # Last 3 exchanges
        for msg in recent_history:
            role = "ì‚¬ìš©ì" if msg.role == "user" else "ì±—ë´‡"
            history_text += f"{role}: {msg.content}\n"
    
    # Prepare stock context
    context_text = ""
    if stock_context:
        context_text = f"\ní˜„ì¬ ëŒ€í™” ì¤‘ì¸ ì¢…ëª©: {stock_context.get('name', 'ì—†ìŒ')} ({stock_context.get('code', 'ì—†ìŒ')})"
    
    # Create prompt
    prompt = f"""ë‹¹ì‹ ì€ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹¤ìŒ ê¸ˆìœµ íˆ¬ì ì±—ë´‡ì…ë‹ˆë‹¤.

**ì—­í• :**
- ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•©ë‹ˆë‹¤
- ì£¼ì‹/íˆ¬ìì— ê´€í•œ ì§ˆë¬¸ì—ëŠ” ë‹¤ìŒ ê¸ˆìœµ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•  ìˆ˜ ìˆìŒì„ ì•ˆë‚´í•©ë‹ˆë‹¤
- ì¹œì ˆí•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤

**ëŒ€í™” ê¸°ë¡:**
{history_text}

**í˜„ì¬ ìƒí™©:**{context_text}

**ì‚¬ìš©ì ì…ë ¥:** {user_input}

**ì‘ë‹µ ê°€ì´ë“œ:**
1. ì¸ì‚¬ë§ì—ëŠ” ì¹œê·¼í•˜ê²Œ ë‹µí•˜ê³  ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ì§€ ë¬¼ì–´ë´…ë‹ˆë‹¤
2. ê°ì‚¬ ì¸ì‚¬ì—ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì‘ëŒ€í•©ë‹ˆë‹¤
3. ì¼ë°˜ ì§ˆë¬¸ì—ëŠ” ì±—ë´‡ì˜ ê¸°ëŠ¥ì„ ê°„ë‹¨íˆ ì„¤ëª…í•©ë‹ˆë‹¤
4. 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤
5. ì´ëª¨ì§€ëŠ” ì ì ˆíˆ ì‚¬ìš©í•©ë‹ˆë‹¤ (ğŸ˜Š, ğŸ“ˆ, ğŸ’¡ ë“±)

ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:"""

    try:
        # Use Anthropic Claude
        if get_env('ANTHROPIC_API_KEY'):
            import anthropic
            
            client = anthropic.Anthropic(api_key=get_env('ANTHROPIC_API_KEY'))
            
            message = client.messages.create(
                model="claude-3-5-sonnet-20241022",
                max_tokens=500,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}]
            )
            
            return message.content[0].text
        
        # Use OpenAI
        elif get_env('OPENAI_API_KEY'):
            from openai import OpenAI
            
            client = OpenAI(api_key=get_env('OPENAI_API_KEY'))
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                max_tokens=500,
                temperature=0.7,
                messages=[{"role": "user", "content": prompt}]
            )
            
            return response.choices[0].message.content
        
        # Fallback
        return _generate_fallback_response(user_input, stock_context)
        
    except Exception as e:
        print(f"Error in conversational response: {e}")
        return _generate_fallback_response(user_input, stock_context)


def _generate_fallback_response(user_input: str, stock_context: Optional[dict] = None) -> str:
    """
    Generate fallback response without LLM
    
    Args:
        user_input: User's input text
        stock_context: Current stock context
        
    Returns:
        Fallback response text
    """
    user_input_lower = user_input.lower()
    
    # Greetings
    if any(word in user_input_lower for word in ['ì•ˆë…•', 'í•˜ì´', 'í—¬ë¡œ', 'ë°˜ê°€']):
        if stock_context:
            return f"ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š\n\ní˜„ì¬ **{stock_context['name']}** ì¢…ëª©ì— ëŒ€í•´ ëŒ€í™” ì¤‘ì´ì‹œë„¤ìš”. ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!"
        else:
            return "ì•ˆë…•í•˜ì„¸ìš”! ë‹¤ìŒ ê¸ˆìœµ íˆ¬ì ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ˜Š\n\nì¢…ëª© ì •ë³´, ì‹œì„¸, ë‰´ìŠ¤ ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"
    
    # Thanks
    if any(word in user_input_lower for word in ['ê³ ë§ˆ', 'ê°ì‚¬', 'ë•¡í', 'ã„³']):
        return "ì²œë§Œì—ìš”! ğŸ˜Š ë‹¤ë¥¸ ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”."
    
    # Help
    if any(word in user_input_lower for word in ['ë„ì›€', 'ì‚¬ìš©ë²•', 'ê¸°ëŠ¥', 'ì–´ë–»ê²Œ']):
        return """**ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ**

ì´ë ‡ê²Œ ë¬¼ì–´ë³´ì„¸ìš”:
- "ì‚¼ì„±ì „ì ì£¼ê°€ëŠ”?" (ì‹œì„¸ í™•ì¸)
- "ë„¤ì´ë²„ ë‰´ìŠ¤ ë³´ì—¬ì¤˜" (ë‰´ìŠ¤ í™•ì¸)
- "ì¹´ì¹´ì˜¤ ì‚¬ë©´ ì¢‹ì„ê¹Œ?" (íˆ¬ì ì •ë³´)
- "í‚¤ì›€ì¦ê¶Œ ì˜ê²¬ì€?" (íˆ¬ìì ì˜ê²¬)

ì¢…ëª©ëª… ë˜ëŠ” 6ìë¦¬ ì½”ë“œë¥¼ ì…ë ¥í•˜ì‹œë©´ ë©ë‹ˆë‹¤!"""
    
    # Goodbye
    if any(word in user_input_lower for word in ['ì˜ê°€', 'ì•ˆë…•íˆ', 'ë°”ì´', 'bye']):
        return "ì•ˆë…•íˆ ê°€ì„¸ìš”! ì¢‹ì€ íˆ¬ì ë˜ì‹œê¸¸ ë°”ëë‹ˆë‹¤. ğŸ“ˆ"
    
    # Default
    if stock_context:
        return f"í˜„ì¬ **{stock_context['name']}** ì¢…ëª©ì— ëŒ€í•´ ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?\n\nì˜ˆ: í˜„ì¬ê°€ëŠ”? / ë‰´ìŠ¤ ë³´ì—¬ì¤˜ / íˆ¬ì ì˜ê²¬ì€?"
    else:
        return "ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ğŸ˜Š\n\nì¢…ëª©ëª…ì„ ë§ì”€í•´ì£¼ì‹œë©´ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì•„ë“œë¦´ê²Œìš”.\n\nì˜ˆ: ì‚¼ì„±ì „ì, ë„¤ì´ë²„, ì¹´ì¹´ì˜¤"


def should_use_conversational_mode(user_input: str, stock_context: Optional[dict] = None) -> bool:
    """
    Decide whether to use conversational mode or stock query mode
    
    Args:
        user_input: User's input text
        stock_context: Current stock context
        
    Returns:
        True if conversational mode should be used
    """
    # Very short inputs
    if len(user_input.strip()) < 2:
        return True
    
    # Check for general conversation
    if is_general_conversation(user_input):
        return True
    
    # Check if it's a follow-up question that needs context
    follow_up_words = ['ê·¸ë˜ì„œ', 'ê·¸ëŸ¼', 'ê·¸ëŸ°ë°', 'ê·¼ë°', 'ê·¸ë¦¬ê³ ', 'ë˜', 'ë”', 'ì¶”ê°€ë¡œ']
    starts_with_followup = any(user_input.startswith(word) for word in follow_up_words)
    
    # If starts with follow-up word and has stock context, use conversational mode
    if starts_with_followup and stock_context:
        return False  # Actually, we want to continue with stock context
    
    return False
