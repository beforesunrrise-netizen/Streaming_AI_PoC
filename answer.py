"""
4-step answer generation
"""

import os
from typing import List

from intent import IntentResult
from planner import FetchPlan
from summarizer import SourceSummary
from config import (
    QUESTION_TYPE_BUY_RECOMMENDATION,
    QUESTION_TYPE_PRICE_STATUS,
    QUESTION_TYPE_PUBLIC_OPINION,
    QUESTION_TYPE_NEWS_DISCLOSURE,
    QUESTION_TYPE_OTHER,
    get_env
)


def _get_intent_description(question_type: str) -> str:
    """
    Get human-readable description of question type
    Args:
        question_type: Question type code
    Returns:
        Description string
    """
    descriptions = {
        QUESTION_TYPE_BUY_RECOMMENDATION: "ë§¤ìˆ˜/íˆ¬ì íŒë‹¨ì— ëŒ€í•œ ì •ë³´ë¥¼ ì›í•˜ì‹œëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤",
        QUESTION_TYPE_PRICE_STATUS: "í˜„ì¬ ì‹œì„¸ ë° ê°€ê²© ì •ë³´ë¥¼ í™•ì¸í•˜ê³ ì í•˜ì‹œëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤",
        QUESTION_TYPE_PUBLIC_OPINION: "ë‹¤ë¥¸ íˆ¬ììë“¤ì˜ ì˜ê²¬ê³¼ ë°˜ì‘ì„ ì•Œê³  ì‹¶ìœ¼ì‹  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤",
        QUESTION_TYPE_NEWS_DISCLOSURE: "ìµœê·¼ ë‰´ìŠ¤ ë° ê³µì‹œ ë‚´ìš©ì„ í™•ì¸í•˜ê³ ì í•˜ì‹œëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤",
        QUESTION_TYPE_OTHER: "ì¢…ëª©ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì •ë³´ë¥¼ ì›í•˜ì‹œëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤"
    }
    return descriptions.get(question_type, "ì§ˆë¬¸ ì˜ë„ë¥¼ íŒŒì•…í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤")


def _generate_final_answer_basic(
    intent: IntentResult,
    summaries: List[SourceSummary]
) -> str:
    """
    Generate final answer using template (basic mode)
    Args:
        intent: Intent analysis result
        summaries: Source summaries
    Returns:
        Final answer text
    """
    question_type = intent.question_type

    # Extract key data from summaries
    price_data = None
    news_data = None
    talks_data = None

    for summary in summaries:
        # Match price data from any source (HTML, API)
        if "ì‹œì„¸ ì •ë³´" in summary.source_type:
            price_data = summary
        elif summary.source_type == "ë‰´ìŠ¤":
            news_data = summary
        elif summary.source_type == "í† ë¡ /ì˜ê²¬":
            talks_data = summary

    # Generate answer based on question type
    if question_type == QUESTION_TYPE_BUY_RECOMMENDATION:
        answer = "**[ë‹¤ìŒ ê¸ˆìœµ ë°ì´í„° ê¸°ë°˜ ë¶„ì„]**\n\n"

        if price_data:
            answer += f"**í˜„ì¬ ìƒíƒœ:**\n{price_data.evidence_snippet}\n\n"

        if news_data:
            answer += f"**ìµœê·¼ ë‰´ìŠ¤:**\n{news_data.evidence_snippet}\n\n"

        if talks_data:
            answer += f"**íˆ¬ìì ì˜ê²¬:**\n{talks_data.evidence_snippet}\n\n"

        answer += "**ì²´í¬í¬ì¸íŠ¸:**\n"
        answer += "- ìœ„ ì •ë³´ëŠ” ë‹¤ìŒ ê¸ˆìœµì—ì„œ ìˆ˜ì§‘í•œ í˜„ì¬ ì‹œì  ë°ì´í„°ì…ë‹ˆë‹¤\n"
        answer += "- íˆ¬ì ê²°ì •ì€ ë³¸ì¸ì˜ íˆ¬ì ì„±í–¥ê³¼ ì¬ë¬´ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ ì‹ ì¤‘íˆ ê²°ì •í•˜ì„¸ìš”\n"
        answer += "- ì¶”ê°€ë¡œ ê¸°ì—… ì¬ë¬´ì œí‘œ, ì—…ì¢… ë™í–¥ ë“±ì„ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤\n"

    elif question_type == QUESTION_TYPE_PRICE_STATUS:
        answer = "**[í˜„ì¬ ì‹œì„¸ ì •ë³´]**\n\n"

        if price_data:
            answer += f"{price_data.evidence_snippet}\n\n"
        else:
            answer += "ì‹œì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"

        answer += "*â€» ì‹¤ì‹œê°„ ë°ì´í„°ê°€ ì•„ë‹ ìˆ˜ ìˆìœ¼ë©°, ì •í™•í•œ ì •ë³´ëŠ” ë‹¤ìŒ ê¸ˆìœµ ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”.*\n"

    elif question_type == QUESTION_TYPE_PUBLIC_OPINION:
        answer = "**[íˆ¬ìì ì˜ê²¬ ìš”ì•½]**\n\n"

        if talks_data:
            answer += f"{talks_data.evidence_snippet}\n\n"
        else:
            answer += "ìµœê·¼ ì˜ê²¬ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"

        if price_data:
            answer += f"**ì°¸ê³  - í˜„ì¬ ì‹œì„¸:**\n{price_data.evidence_snippet}\n\n"

        answer += "*â€» ê°œì¸ ì˜ê²¬ì´ë¯€ë¡œ ì°¸ê³ ë§Œ í•˜ì‹œê³ , íˆ¬ì íŒë‹¨ì€ ë³¸ì¸ì˜ ì±…ì„í•˜ì— í•˜ì„¸ìš”.*\n"

    elif question_type == QUESTION_TYPE_NEWS_DISCLOSURE:
        answer = "**[ìµœê·¼ ë‰´ìŠ¤ ë° ê³µì‹œ]**\n\n"

        if news_data:
            answer += f"**ë‰´ìŠ¤:**\n{news_data.evidence_snippet}\n\n"

        found_disclosure = False
        for summary in summaries:
            if summary.source_type == "ê³µì‹œ":
                answer += f"**ê³µì‹œ:**\n{summary.evidence_snippet}\n\n"
                found_disclosure = True
                break

        if not news_data and not found_disclosure:
            answer += "ìµœê·¼ ë‰´ìŠ¤ë‚˜ ê³µì‹œë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"

    else:
        answer = "**[ì¢…ëª© ì •ë³´]**\n\n"

        if price_data:
            answer += f"{price_data.evidence_snippet}\n\n"
        else:
            answer += "ì¢…ëª© ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"

    return answer


def _generate_final_answer_llm(
    intent: IntentResult,
    summaries: List[SourceSummary],
    chat_history: List = None
) -> str:
    """
    Generate final answer using LLM (optional mode)
    Args:
        intent: Intent analysis result
        summaries: Source summaries
        chat_history: Previous chat messages for context (optional)
    Returns:
        Final answer text
    """
    try:
        # Check if OpenAI API key is available
        if not get_env('OPENAI_API_KEY'):
            import logging
            logger = logging.getLogger(__name__)
            logger.info("No OpenAI API key found, using basic template mode")
            return _generate_final_answer_basic(intent, summaries)

        # Prepare evidence snippets
        evidence = "\n\n".join([
            f"[{summary.source_type}]\n{summary.evidence_snippet}"
            for summary in summaries
        ])

        # Check if we have any evidence
        if not evidence.strip():
            import logging
            logger = logging.getLogger(__name__)
            logger.warning("No evidence data available for LLM")
            return _generate_final_answer_basic(intent, summaries)

        # Prepare chat history context
        history_context = ""
        if chat_history and len(chat_history) > 0:
            history_context = "\n**ì´ì „ ëŒ€í™” ë‚´ìš©:**\n"
            for msg in chat_history[-6:]:  # Last 3 exchanges
                # Handle both dict and object formats
                role_value = msg.get('role') if isinstance(msg, dict) else msg.role
                content_value = msg.get('content') if isinstance(msg, dict) else msg.content
                role = "ì‚¬ìš©ì" if role_value == "user" else "ì±—ë´‡"
                history_context += f"{role}: {content_value[:200]}...\n"
            history_context += "\n"

        # Get current date
        from datetime import datetime
        current_date = datetime.now().strftime('%Yë…„ %mì›” %dì¼')
        
        prompt_text = f"""ë‹¹ì‹ ì€ ì´ˆë³´ íˆ¬ììë¥¼ ë•ëŠ” ì¹œì ˆí•œ ì£¼ì‹ ê°€ì´ë“œì…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸ˆìœµì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ë¥¼ **ì‰½ê³  ê°„ë‹¨í•˜ê²Œ** ì •ë¦¬í•´ì„œ ì•Œë ¤ì£¼ì„¸ìš”.

**ì˜¤ëŠ˜ ë‚ ì§œ:** {current_date}

{history_context}**ì¢…ëª©:** {intent.stock_name} ({intent.stock_code})

**ìˆ˜ì§‘í•œ ì •ë³´:**
{evidence}

---

## ğŸ“ ë‹µë³€ ì‘ì„± ê°€ì´ë“œ

**ë§¤ìš° ì¤‘ìš” - ë‹µë³€ ìˆœì„œ:**
1. **ê²°ë¡ ë¶€í„° ë¨¼ì € ë§í•˜ê¸°** (ê°€ì¥ ìœ„ì—)
2. ê·¸ ë‹¤ìŒì— ì´ìœ /ê·¼ê±° ì„¤ëª…

**ë‹µë³€ êµ¬ì¡°:**

### âœ… ê²°ë¡  (ì œì¼ ë¨¼ì €!)
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ **ì²« ë¬¸ì¥ì— ë°”ë¡œ** ì œì‹œ
- ì˜ˆ: "ì‚¼ì„±ì „ìëŠ” í˜„ì¬ ìƒìŠ¹ì„¸ë¥¼ ë³´ì´ê³  ìˆì–´ ê¸ì •ì ìœ¼ë¡œ í‰ê°€ë©ë‹ˆë‹¤"
- ì˜ˆ: "ë„¤ì´ë²„ëŠ” ìµœê·¼ ì•½ì„¸ë¥¼ ë³´ì´ê³  ìˆì–´ ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•´ ë³´ì…ë‹ˆë‹¤"
- ë‹¨, ì§ì ‘ì ì¸ "ì‚¬ì„¸ìš”/íŒŒì„¸ìš”" í‘œí˜„ì€ ê¸ˆì§€

### ğŸ“Š í˜„ì¬ ìƒí™© ({current_date} ê¸°ì¤€)
- í˜„ì¬ê°€, ë“±ë½ë¥ ì„ **í•œ ì¤„ë¡œ** ê°„ë‹¨íˆ
- ì˜ˆ: "í˜„ì¬ 50,000ì›ìœ¼ë¡œ ì „ì¼ ëŒ€ë¹„ 2% ìƒìŠ¹ ì¤‘ì…ë‹ˆë‹¤"

### ğŸ“° ì£¼ìš” ì´ìœ /ê·¼ê±°
- ë‰´ìŠ¤ë‚˜ ë¦¬í¬íŠ¸ì˜ **í•µì‹¬ ë‚´ìš©ë§Œ** 2-3ì¤„ë¡œ ìš”ì•½
- ëª©í‘œê°€ë‚˜ ì‹¤ì  ê°™ì€ ì¤‘ìš”í•œ ìˆ«ì í¬í•¨
- ì˜ˆ: "ì¦ê¶Œì‚¬ì—ì„œ ëª©í‘œê°€ 60,000ì›ì„ ì œì‹œí–ˆê³ , ì‹¤ì  ê°œì„ ì´ ì˜ˆìƒë©ë‹ˆë‹¤"

### ğŸ’¬ ì‹œì¥ ë°˜ì‘
- íˆ¬ììë“¤ì˜ ì˜ê²¬ì„ **í•œ ì¤„ë¡œ**
- ì˜ˆ: "íˆ¬ììë“¤ì€ ëŒ€ì²´ë¡œ ê¸ì •ì ì¸ ë°˜ì‘ì…ë‹ˆë‹¤"

### âš ï¸ ì°¸ê³ 
- íˆ¬ì ìœ ì˜ì‚¬í•­ í•œ ë¬¸ì¥

**ì‘ì„± ê·œì¹™:**
- âœ… **ê²°ë¡ ì„ ë§¨ ì²˜ìŒì— ë¨¼ì € ë§í•˜ê¸°**
- âœ… {current_date} ê¸°ì¤€ ë°ì´í„°ì„ì„ ëª…ì‹œ
- âœ… ì‰¬ìš´ ë§ë¡œ ì§§ê³  ëª…í™•í•˜ê²Œ
- âœ… í•µì‹¬ë§Œ ê°„ì¶”ë ¤ì„œ
- âŒ "ë§¤ìˆ˜í•˜ì„¸ìš”" ê°™ì€ ì§ì ‘ ê¶Œìœ  ê¸ˆì§€
- âŒ "~í•  ê²ƒì…ë‹ˆë‹¤" ê°™ì€ í™•ì • ì˜ˆì¸¡ ê¸ˆì§€

---

ìœ„ ê°€ì´ë“œì— ë”°ë¼ **ê²°ë¡ ë¶€í„° ë¨¼ì € ì œì‹œí•˜ê³ , ê·¸ ë‹¤ìŒ ê·¼ê±°ë¥¼ ì„¤ëª…í•˜ëŠ” ë‹µë³€**ì„ ì‘ì„±í•˜ì„¸ìš”:"""

        # Use OpenAI API
        from openai import OpenAI
        from config import LLM_MODEL_OPENAI, LLM_MAX_TOKENS, LLM_TEMPERATURE
        import logging
        logger = logging.getLogger(__name__)

        logger.info(f"Calling OpenAI API with model: {LLM_MODEL_OPENAI}")
        
        client = OpenAI(api_key=get_env('OPENAI_API_KEY'))

        response = client.chat.completions.create(
            model=LLM_MODEL_OPENAI,
            max_completion_tokens=LLM_MAX_TOKENS,
            messages=[{"role": "user", "content": prompt_text}]
        )

        logger.info("OpenAI API call successful")
        return response.choices[0].message.content

    except Exception as e:
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"LLM answer generation failed: {str(e)}", exc_info=True)
        logger.info("Falling back to basic template mode")
        return _generate_final_answer_basic(intent, summaries)


def generate_answer(
    intent: IntentResult,
    plans: List[FetchPlan],
    summaries: List[SourceSummary],
    use_llm: bool = False,
    show_details: bool = True,
    chat_history: List = None
) -> str:
    """
    Generate 4-step structured answer

    Args:
        intent: Intent analysis result
        plans: Fetch plans
        summaries: Source summaries
        use_llm: Whether to use LLM for answer generation (default: False)
        show_details: Whether to show detailed steps 1-3 (default: True)
        chat_history: Previous chat messages for context (optional)

    Returns:
        Complete answer as markdown string
    """
    output = []

    # Show detailed steps only if requested
    if show_details:
        # Step 1: Intent Analysis
        output.append("### [1] ì§ˆë¬¸ ì˜ë„ ë¶„ì„\n")
        output.append(f"- **ì§ˆë¬¸ ìœ í˜•:** {intent.question_type}")
        output.append(f"- **ëŒ€ìƒ ì¢…ëª©:** {intent.stock_name or 'í™•ì¸ ë¶ˆê°€'} ({intent.stock_code or 'í™•ì¸ ë¶ˆê°€'})")
        output.append(f"- **ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ê²ƒ:** {_get_intent_description(intent.question_type)}\n")

        # Step 2: Exploration Plan
        output.append("### [2] ë‹¤ìŒ ê¸ˆìœµ íƒìƒ‰ ê³„íš\n")
        if plans:
            for i, plan in enumerate(plans, 1):
                output.append(f"- **Plan {i}:** {plan.description}")
                output.append(f"  - URL: `{plan.url}`")
        else:
            output.append("- íƒìƒ‰ ê³„íšì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì¢…ëª© ì •ë³´ ë¶€ì¡±)\n")
        output.append("")

        # Step 3: Scraping Results Summary
        output.append("### [3] ë‹¤ìŒ ê¸ˆìœµ ìŠ¤í¬ë© ê²°ê³¼ ìš”ì•½\n")
        if summaries:
            for i, summary in enumerate(summaries, 1):
                output.append(f"**Source {i}: {summary.source_type}**")
                output.append(f"- URL: `{summary.source_url}`")
                output.append(f"- ê·¼ê±° ìŠ¤ë‹ˆí«:\n```\n{summary.evidence_snippet}\n```\n")
        else:
            output.append("- ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n")

        # Step 4: Final Answer
        output.append("### [4] ìµœì¢… ë‹µë³€ (ì´ˆë³´ì ì¹œí™”)\n")

    # Generate final answer (always shown)
    if summaries:
        if use_llm:
            final_answer = _generate_final_answer_llm(intent, summaries, chat_history)
        else:
            final_answer = _generate_final_answer_basic(intent, summaries)
        output.append(final_answer)
    else:
        output.append("ì§ˆë¬¸ì— ë‹µë³€í•  ìˆ˜ ìˆëŠ” ì¶©ë¶„í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        output.append("ì¢…ëª© ì½”ë“œë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n")

    # Reference section - ALWAYS show (even when show_details=False)
    # This ensures users can verify all data comes from finance.daum.net
    output.append("\n---")
    
    if show_details:
        output.append("### ğŸ“ ì°¸ê³ í•œ ë‹¤ìŒ ê¸ˆìœµ í˜ì´ì§€\n")
    else:
        output.append("**ğŸ“ ì°¸ê³ í•œ ë‹¤ìŒ ê¸ˆìœµ í˜ì´ì§€**\n")

    if summaries:
        # Collect unique URLs
        reference_urls = []
        seen_urls = set()

        for summary in summaries:
            url = summary.source_url
            if url and url not in seen_urls:
                seen_urls.add(url)
                reference_urls.append({
                    'type': summary.source_type,
                    'url': url
                })

        # Display as clickable links
        if reference_urls:
            for i, ref in enumerate(reference_urls[:7], 1):  # Limit to 7 references
                # Extract a friendly name from URL or use source type
                friendly_name = ref['type'] or f"ì°¸ê³  {i}"
                output.append(f"{i}. [{friendly_name}]({ref['url']})")
        else:
            output.append("- ì°¸ê³  URL ì—†ìŒ")
    else:
        output.append("- ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")

    output.append("")

    # Footer - compact version
    if show_details:
        output.append("---")
        output.append("**âš ï¸ ì£¼ì˜ì‚¬í•­:**")
        output.append("- ë³¸ ì •ë³´ëŠ” ë‹¤ìŒ ê¸ˆìœµ(finance.daum.net) ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤")
        output.append("- íˆ¬ì íŒë‹¨ ë° ê²°ê³¼ì— ëŒ€í•œ ì±…ì„ì€ íˆ¬ìì ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤")
        output.append("- ì‹¤ì‹œê°„ ë°ì´í„°ê°€ ì•„ë‹ ìˆ˜ ìˆìœ¼ë‹ˆ, ì •í™•í•œ ì •ë³´ëŠ” ì§ì ‘ í™•ì¸í•˜ì„¸ìš”")
    else:
        # Minimal footer for clean mode
        output.append("\n\n---")
        output.append("*ë³¸ ì •ë³´ëŠ” ë‹¤ìŒ ê¸ˆìœµ ë°ì´í„° ê¸°ë°˜ì´ë©°, íˆ¬ì íŒë‹¨ì€ ë³¸ì¸ ì±…ì„ì…ë‹ˆë‹¤*")

    return "\n".join(output)
